{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "from cltk.corpus.latin import latinlibrary\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prose authors ('business' prose, as Lyne says; though I added in some Cicero too)\n",
    "\n",
    "caesar = [file for file in latinlibrary.fileids() if 'caesar/' in file]\n",
    "cicero = [file for file in latinlibrary.fileids() if 'cicero/or' in file or 'brut.txt' in file]\n",
    "varro = [file for file in latinlibrary.fileids() if 'varro.rr' in file]\n",
    "livy = [file for file in latinlibrary.fileids() if 'livy/liv.2' in file and file != 'livy/liv.2.txt']\n",
    "vitruvius = [file for file in latinlibrary.fileids() if 'vitru' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prose selection is 3255900 characters long.\n"
     ]
    }
   ],
   "source": [
    "print('The prose selection is {} characters long.'.format(len(latinlibrary.raw(caesar)) + \n",
    "                                                          len(latinlibrary.raw(cicero)) +\n",
    "                                                          len(latinlibrary.raw(varro)) + \n",
    "                                                          len(latinlibrary.raw(livy)) + \n",
    "                                                          len(latinlibrary.raw(vitruvius))\n",
    "                                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verse authors\n",
    "\n",
    "catullus = [file for file in latinlibrary.fileids() if 'catullus' in file]\n",
    "lucretius = [file for file in latinlibrary.fileids() if 'lucr' in file]\n",
    "vergil = [file for file in latinlibrary.fileids() if 'vergil/' in file]\n",
    "propertius = [file for file in latinlibrary.fileids() if file == 'propertius1.txt' or file == 'prop2.txt' or file == 'prop3.txt' or file == 'prop4.txt']\n",
    "ovid = [file for file in latinlibrary.fileids() if 'ovid' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The verse selection is 2813813 characters long.\n"
     ]
    }
   ],
   "source": [
    "print('The verse selection is {} characters long.'.format(len(latinlibrary.raw(catullus)) + \n",
    "                                                          len(latinlibrary.raw(lucretius)) + \n",
    "                                                          len(latinlibrary.raw(vergil)) + \n",
    "                                                          len(latinlibrary.raw(propertius)) +\n",
    "                                                          len(latinlibrary.raw(ovid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ll_content(fileid):\n",
    "    raw = latinlibrary.raw(fileid)\n",
    "    trim = raw[1000:-1000]\n",
    "    trim_start = trim.find(' ')+1\n",
    "    trim_end = trim.rfind(' ')\n",
    "    return trim[trim_start:trim_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_raw = [remove_ll_content(file) for file in caesar]\n",
    "cicero_raw = [remove_ll_content(file) for file in cicero]\n",
    "varro_raw = [remove_ll_content(file) for file in varro]\n",
    "livy_raw = [remove_ll_content(file) for file in livy]\n",
    "vitruvius_raw = [remove_ll_content(file) for file in vitruvius]\n",
    "\n",
    "catullus_raw = [remove_ll_content(file) for file in catullus]\n",
    "lucretius_raw = [remove_ll_content(file) for file in lucretius]\n",
    "vergil_raw = [remove_ll_content(file) for file in vergil]\n",
    "propertius_raw = [remove_ll_content(file) for file in propertius]\n",
    "ovid_raw = [remove_ll_content(file) for file in ovid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for preprocessing texts\n",
    "\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    replacer = JVReplacer()\n",
    "    \n",
    "    text = html.unescape(text) # Handle html entities\n",
    "    text = re.sub(r'&nbsp;?', ' ',text) #&nbsp; stripped incorrectly in corpus?\n",
    "    text = re.sub(r'\\x00',' ',text) #Another space problem?\n",
    "        \n",
    "    text = text.lower()\n",
    "    text = replacer.replace(text) #Normalize u/v & i/j    \n",
    "    \n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!«»\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    text = re.sub('[ ]+',' ', text) # Remove double spaces\n",
    "    text = re.sub('\\s+\\n+\\s+','\\n', text) # Remove double lines and trim spaces around new lines\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_pp = [preprocess(raw) for raw in caesar_raw]\n",
    "cicero_pp = [preprocess(raw) for raw in cicero_raw]\n",
    "varro_pp = [preprocess(raw) for raw in varro_raw]\n",
    "livy_pp = [preprocess(raw) for raw in livy_raw]\n",
    "vitruvius_pp = [preprocess(raw) for raw in vitruvius_raw]\n",
    "\n",
    "catullus_pp = [preprocess(raw) for raw in catullus_raw]\n",
    "lucretius_pp = [preprocess(raw) for raw in lucretius_raw]\n",
    "vergil_pp = [preprocess(raw) for raw in vergil_raw]\n",
    "propertius_pp = [preprocess(raw) for raw in propertius_raw]\n",
    "ovid_pp = [preprocess(raw) for raw in ovid_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_tokens = [text.split() for text in caesar_pp]\n",
    "cicero_tokens = [text.split() for text in cicero_pp]\n",
    "varro_tokens = [text.split() for text in varro_pp]\n",
    "livy_tokens = [text.split() for text in livy_pp]\n",
    "vitruvius_tokens = [text.split() for text in vitruvius_pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of prose words is 443285.\n"
     ]
    }
   ],
   "source": [
    "prose_tokens = caesar_tokens + cicero_tokens + varro_tokens + livy_tokens + vitruvius_tokens\n",
    "print(f'The number of prose words is {sum([len(token) for token in prose_tokens])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "catullus_tokens = [text.split() for text in catullus_pp]\n",
    "lucretius_tokens = [text.split() for text in lucretius_pp]\n",
    "vergil_tokens = [text.split() for text in vergil_pp]\n",
    "propertius_tokens = [text.split() for text in propertius_pp]\n",
    "ovid_tokens = [text.split() for text in ovid_pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of prose words is 365761.\n"
     ]
    }
   ],
   "source": [
    "verse_tokens = catullus_tokens + lucretius_tokens + vergil_tokens + propertius_tokens + ovid_tokens\n",
    "print(f'The number of prose words is {sum([len(token) for token in verse_tokens])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextArray = []\n",
    "\n",
    "for i, text in enumerate(caesar_pp):\n",
    "    TextArray.append(('prose', caesar[i], text))\n",
    "for i, text in enumerate(cicero_pp):\n",
    "    TextArray.append(('prose', cicero[i], text))\n",
    "for i, text in enumerate(varro_pp):\n",
    "    TextArray.append(('prose', varro[i], text))\n",
    "for i, text in enumerate(livy_pp):\n",
    "    TextArray.append(('prose', livy[i], text))    \n",
    "for i, text in enumerate(vitruvius_pp):\n",
    "    TextArray.append(('prose', vitruvius[i], text))\n",
    "for i, text in enumerate(catullus_pp):\n",
    "    TextArray.append(('verse', catullus[i], text))\n",
    "for i, text in enumerate(lucretius_pp):\n",
    "    TextArray.append(('verse', lucretius[i], text))\n",
    "for i, text in enumerate(vergil_pp):\n",
    "    TextArray.append(('verse', vergil[i], text))\n",
    "for i, text in enumerate(propertius_pp):\n",
    "    TextArray.append(('verse', propertius[i], text))    \n",
    "for i, text in enumerate(ovid_pp):\n",
    "    TextArray.append(('verse', ovid[i], text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Text Array to pickle\n",
    "\n",
    "pickle.dump(TextArray, open(\"./data/text_array.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for chunking text\n",
    "\n",
    "def make_text_chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build chunked TextArray\n",
    "\n",
    "TextArrayChunks = []\n",
    "\n",
    "for item in TextArray:\n",
    "    mode, work, text = item\n",
    "    tokens = text.split() \n",
    "    chunk_text = make_text_chunks(tokens, 250)\n",
    "    chunk_text = [\" \".join(chunk) for chunk in chunk_text]\n",
    "    for i, chunk in enumerate(list(chunk_text)):\n",
    "        chunk_name = '{}_{}'.format(work, i)\n",
    "        TextArrayChunks.append((mode, work, chunk_name, chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('prose',\n",
       " 'caesar/alex.txt',\n",
       " 'caesar/alex.txt_1',\n",
       " 'acutissimi quae a nobis fieri uiderant ea sollertia efficiebant ut nostri illorum opera imitati uiderentur et sua sponte multa reperiebant unoque tempore et nostras munitiones infestabant et suas defendebant atque haec principes in consiliis contionibusque agitabant populum romanum paulatim in consuetudinem eius regni occupandi uenire paucis annis ante a gabinium cum exercitu fuisse in aegypto pompeium se ex fuga eodem recepisse caesarem uenisse cum copiis neque morte pompei quicquam profectum quo minus apud se caesar commoraretur quem si non expulissent futuram ex regno prouinciam idque agendum mature namque eum interclusum tempestatibus propter anni tempus recipere transmarina auxilia non posse interim dissensione orta inter achillan qui ueterano exercitui praeerat et arsinoen regis ptolomaei minorem filiam ut supra demonstratum est cum uterque utrique insidiaretur et summam imperi ipse obtinere uellet praeoccupat arsinoe per ganymeden eunuchum nutricium suum atque achillan interficit hoc occiso sine ullo socio et custode ipsa omne imperium obtinebat exercitus ganymedi traditur is suscepto officio largitionem in militem auget reliqua pari diligentia administrat alexandrea est fere tota suffossa specusque habet a nilo pertinentis quibus aqua in priuatas domos inducitur quae paulatim spatio temporis liquescit ac subsidit hac uti domini aedificiorum atque eorum familiae consuerunt nam quae flumine nilo fertur adeo est limosa ac turbida ut multos uariosque morbos efficiat sed ea plebes ac multitudo contenta est necessario quod fons urbe tota nullus est hoc tamen flumen in ea parte erat urbis quae ab alexandrinis tenebatur quo facto est admonitus ganymedes posse nostros aqua intercludi qui distributi munitionum tuendarum causa uicatim')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextArrayChunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Chunked Text Array to pickle\n",
    "\n",
    "pickle.dump(TextArrayChunks, open(\"./data/text_array_chunks.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
